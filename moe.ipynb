{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-16T12:49:11.504292Z",
     "start_time": "2025-02-16T12:49:10.919949Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Basic MoE",
   "id": "6517cc2c3dfe28a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T12:49:12.091653Z",
     "start_time": "2025-02-16T12:49:12.088258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BasicExpert(nn.Module):\n",
    "    def __init__(self, feature_in, feature_out):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(feature_in, feature_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ],
   "id": "1497a767b4ead2a0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T12:49:12.261310Z",
     "start_time": "2025-02-16T12:49:12.258214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BasicMoe(nn.Module):\n",
    "    def __init__(self, feature_in, feature_out, num_expert):\n",
    "        super().__init__()\n",
    "        self.gate = nn.Linear(feature_in, num_expert) # 门控网络，把输入数据映射为 num_expert 维的权重分数\n",
    "        self.experts = nn.ModuleList(\n",
    "            BasicExpert(\n",
    "                feature_in, feature_out\n",
    "            ) for _ in range(num_expert)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 计算每个 expert 的权重分数，并得到每个 expert 的输出\n",
    "        expert_weights = self.gate(x) # (batch size, feature in) -> (batch size, num expert)\n",
    "        expert_out_list = [\n",
    "            expert(x) for expert in self.experts\n",
    "        ] # 每个 expert 输出一个 (batch size, feature out)\n",
    "\n",
    "        expert_outputs = [\n",
    "            expert_out.unsqueeze(1) for expert_out in expert_out_list\n",
    "        ] # 把每个 expert out 变为 (batch size, 1, feature out)\n",
    "\n",
    "        expert_output = torch.concat(\n",
    "            expert_outputs, dim=1\n",
    "        ) # 堆叠为 (batch size, num experts, feature out)\n",
    "\n",
    "        expert_weights = F.softmax(expert_weights, dim=-1) # (batch size, num experts)\n",
    "\n",
    "        expert_weights = expert_weights.unsqueeze(1) # (batch size, 1, num experts)\n",
    "        # 目标输出是 (batch, feature_out)\n",
    "        output = expert_weights @ expert_output # (batch size, 1, feature out)\n",
    "        return output.squeeze(1) # (batch size, feature out)"
   ],
   "id": "2812654318bc2467",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T12:49:12.420322Z",
     "start_time": "2025-02-16T12:49:12.418225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_basic_moe():\n",
    "    x = torch.rand(4, 512)\n",
    "    basic_moe = BasicMoe(512, 128, 4)\n",
    "    output = basic_moe(x)\n",
    "    print(output.shape)"
   ],
   "id": "687df850394dd9b0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T12:49:12.582034Z",
     "start_time": "2025-02-16T12:49:12.577373Z"
    }
   },
   "cell_type": "code",
   "source": "test_basic_moe()",
   "id": "6fb3173976e50112",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 128])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### SparseMoE\n",
    "\n",
    "SparseMoE 和 BasicMoE 的区别是，它会选择 top K 个专家，而非所有的专家，然后对这 top K 个专家的输出进行加权求和"
   ],
   "id": "65c705e24f08d48b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T12:49:12.978401Z",
     "start_time": "2025-02-16T12:49:12.968687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MOEConfig:\n",
    "    def __init__(self, hidden_dim, expert_number, top_k, shared_experts_number=2):\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.expert_number = expert_number\n",
    "        self.top_k = top_k\n",
    "        self.shared_experts_number = shared_experts_number\n",
    "\n",
    "class MOERouter(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.gate = nn.Linear(config.hidden_dim, config.expert_number)\n",
    "\n",
    "        # 但后面只会选择 top k 个专家\n",
    "        self.expert_number = config.expert_number\n",
    "        self.top_k = config.top_k\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 假设 expert number 是 8，top k 是 2\n",
    "        router_logits = self.gate(x) # (batch_size, expert number)\n",
    "\n",
    "        # 计算每一个专家的概率\n",
    "        router_probs = F.softmax(router_logits, dim=1, dtype=torch.float32)\n",
    "\n",
    "        # 计算 top k 专家的输出\n",
    "        # top k 是可以反向传播的\n",
    "        router_weights, selected_experts_indices = torch.topk(router_probs, self.top_k, dim=-1)\n",
    "        # 这两个的 shape 都是 (batch_size * seq_len, top_k)\n",
    "\n",
    "        # 选出 top k 个 expert 之后重新计算各自权重，此处使用归一化\n",
    "        router_weights = router_weights / router_weights.sum(\n",
    "            dim=-1, keepdim=True\n",
    "        )\n",
    "        router_weights = router_weights.to(x.dtype)\n",
    "\n",
    "        expert_mask = F.one_hot(\n",
    "            selected_experts_indices,\n",
    "            num_classes=self.expert_number\n",
    "        ) # (batch_size * seq_len, top_k, expert_number)\n",
    "        expert_mask = expert_mask.permute(2, 1, 0) # (expert_number, top_k, batch_size * seq_len)\n",
    "\n",
    "        return router_logits, router_weights, selected_experts_indices, expert_mask\n",
    "\n",
    "class SparseMOE(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.top_k = config.top_k\n",
    "        self.hidden_dim = config.hidden_dim\n",
    "        self.expert_number = config.expert_number\n",
    "\n",
    "        # 初始化专家\n",
    "        self.experts = nn.ModuleList(\n",
    "            BasicExpert(\n",
    "                config.hidden_dim,\n",
    "                config.hidden_dim\n",
    "            ) for _ in range(config.expert_number)\n",
    "        )\n",
    "        self.router = MOERouter(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch size, seq_len , hidden_dim)\n",
    "        batch_size, seq_len, hidden_dim = x.size()\n",
    "\n",
    "        # 因为是要对 token 进行维度计算，所以 x reshape -> (batch_size * seq_len, hidden_dim)\n",
    "        hidden_states = x.view(-1, hidden_dim)\n",
    "\n",
    "        # 相关的专家计算\n",
    "        router_logits, router_weights, selected_experts_indices, expert_masks = self.router(\n",
    "            hidden_states\n",
    "        )\n",
    "        # expert_mask shape -> (expert_number, top_k, batch_size * seq_len)\n",
    "\n",
    "        final_hidden_states = torch.zeros(\n",
    "            (batch_size * seq_len, hidden_dim),\n",
    "            dtype=hidden_states.dtype,\n",
    "            device=hidden_states.device\n",
    "        )\n",
    "\n",
    "        # 遍历每个 expert，把选中的 expert 的计算结果 (hidden states) 加到 final hidden states\n",
    "        for expert_idx in range(self.expert_number):\n",
    "            expert_layer = self.experts[expert_idx]\n",
    "\n",
    "            current_expert_mask = expert_masks[expert_idx]\n",
    "\n",
    "            router_weights_idx, top_x = torch.where(current_expert_mask) # idx 是 0 或 1\n",
    "\n",
    "            current_state = hidden_states.unsqueeze(0)[:, top_x, :].reshape(-1, hidden_dim) # (selected_token_number, hidden_dim)\n",
    "            current_state = expert_layer(current_state)\n",
    "\n",
    "            current_token_router_weight = router_weights[top_x, router_weights_idx] # (selected_token_number)\n",
    "            current_token_router_weight = current_token_router_weight.unsqueeze(-1) # (selected_token_number, 1)\n",
    "\n",
    "            current_hidden_states = current_state * current_token_router_weight # (selected_token_number, hidden_dim)\n",
    "\n",
    "            final_hidden_states.index_add_( # 加下划线表示原地操作\n",
    "                0,\n",
    "                top_x,\n",
    "                current_hidden_states.to(hidden_states.dtype)\n",
    "            )\n",
    "        # 把 final hidden states 还原到原来的 shape\n",
    "        final_hidden_states = final_hidden_states.reshape(batch_size, seq_len, hidden_dim)\n",
    "\n",
    "        return final_hidden_states, router_logits\n",
    "\n",
    "def test_token_level_moe():\n",
    "    x = torch.rand(2, 4, 16)\n",
    "    config = MOEConfig(16, 2, 2)\n",
    "    token_level_moe = SparseMOE(config)\n",
    "    out = token_level_moe(x)\n",
    "    print(out[0].shape, out[1].shape)\n",
    "\n",
    "test_token_level_moe()"
   ],
   "id": "cb144c6e4c2e7e51",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 16]) torch.Size([8, 2])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ShareExpert SparseMoe",
   "id": "ac9d8a2d0953fc7a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T12:56:20.256877Z",
     "start_time": "2025-02-16T12:56:20.249137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SharedExpertMOE(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.routed_experts_moe = SparseMOE(config)\n",
    "        self.shared_experts = nn.ModuleList(\n",
    "            [\n",
    "                BasicExpert(\n",
    "                    config.hidden_dim,\n",
    "                    config.hidden_dim,\n",
    "                )\n",
    "                for _ in range(config.shared_experts_number)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, hidden_dim = x.size()\n",
    "\n",
    "        shared_experts_output_list = [\n",
    "            expert(x) for expert in self.shared_experts\n",
    "        ]\n",
    "        shared_experts_output = torch.stack(\n",
    "            shared_experts_output_list,\n",
    "            dim = 0,\n",
    "        ) # (shared_experts_number, batch_size, seq_len, hidden_dim)\n",
    "\n",
    "        shared_expert_out = shared_experts_output.sum(dim=0, keepdim=False)\n",
    "\n",
    "        sparse_moe_out, router_logits = self.routed_experts_moe(\n",
    "            x\n",
    "        )\n",
    "\n",
    "        output = shared_expert_out + sparse_moe_out\n",
    "        return output, router_logits\n",
    "\n",
    "def test_share_expert_moe():\n",
    "    x = torch.rand(2, 4, 16)\n",
    "    config = MOEConfig(16, 2, 2)\n",
    "    share_expert_moe = SharedExpertMOE(config)\n",
    "    out = share_expert_moe(x)\n",
    "    print(out[0].shape, out[1].shape)\n",
    "\n",
    "test_share_expert_moe()"
   ],
   "id": "120f3a085b5aef81",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 16]) torch.Size([8, 2])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T12:49:14.132244Z",
     "start_time": "2025-02-16T12:49:14.130961Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "aedae25f81abb6c2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
